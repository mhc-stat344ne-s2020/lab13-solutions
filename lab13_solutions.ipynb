{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab13_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ6UU3Ay8vdZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Introduction\n",
        "\n",
        "In this lab we will use YOLO to detect raccoons!\n",
        "\n",
        "This lab is adapted from the following sources:\n",
        "\n",
        " * https://github.com/experiencor/keras-yolo3\n",
        " * https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras/\n",
        "\n",
        "The `keras-yolo3` repository provides utility functions to facilitate working with the YOLO model in Keras.  I basically took that code and deleted important parts of it for you to fill in :)\n",
        "\n",
        "# Package imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyD5alyF8gzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "import struct\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm53u7K9gcdq",
        "colab_type": "text"
      },
      "source": [
        "# Set up google drive\n",
        "\n",
        "Since the YOLO model takes a long time to fit, we will use pre-estimated model weights and see how the process of using the model to generate predictions works.\n",
        "\n",
        "As usual, I have shared the necessary files with you in a google drive folder.  To get the data into colab, do these steps:\n",
        "\n",
        "1. Sign into drive.google.com\n",
        "2. Click on \"Shared with me\" on the left side of the screen\n",
        "3. Right click on the stat344ne_yolo folder and select \"Add Shortcut to Drive\"\n",
        "4. Run the code cell below and click on the link that is displayed.  It will pop up a new browser tab where you have to authorize Colab to access your google drive.  Then, copy the sequence of numbers and letters that is displayed and paste it in the space that shows up in the code cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Zj475ehdiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "48ca65fb-9361-4cda-94ae-f36f1d7d78c6"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9LZJEUthiZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"/content/stat344ne_yolo/\")\n",
        "#!unzip -uq \"/content/drive/My Drive/stat344ne_yolo/cats_and_dogs_small.zip\" -d \"/content/stat344ne_yolo/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTGW70unqU4m",
        "colab_type": "text"
      },
      "source": [
        "# Load saved YOLO version 3 model fit\n",
        "\n",
        "This is saved in the file `yolov3_keras.h5` in the google drive folder.  The model weights were downloaded from the official YOLO website and loaded into a Keras model using code provided in the https://github.com/experiencor/keras-yolo3 repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddE2S_CQqTbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolov3 = load_model('/content/drive/My Drive/stat344ne_yolo/yolov3_keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tkI8-X7Sb7",
        "colab_type": "text"
      },
      "source": [
        "# Utility functions\n",
        "\n",
        "### Utility functions to generate predictions -- run as is\n",
        "\n",
        "The following code is from https://github.com/experiencor/keras-yolo3.  I'm not asking you to make any changes to the code in the next cell, you can run it as is.  You might just read the function documentation and see what each function does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EERTrW0q7Ru-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoundBox:\n",
        "    '''\n",
        "    A class to represent bounding boxes.  The boxes are represented by:\n",
        "     - (xmin, ymin): the coordinates of the top left corner\n",
        "     - (xmax, ymax): the coordinates of the lower right corner\n",
        "     - objness: optionally an estimated probability that the box contains an\n",
        "       object\n",
        "     - classes: optionally an estimated probability of class\n",
        "    '''\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "\n",
        "def preprocess_input(image, net_h, net_w):\n",
        "    '''\n",
        "    resize an input image to the dimensions required by the input layer for the\n",
        "    yolo model\n",
        "\n",
        "    Arguments:\n",
        "     - image: a numpy array with an input image\n",
        "     - net_h: input height required for neural network\n",
        "     - net_w: input width required for neural network\n",
        "    '''\n",
        "    new_h, new_w, _ = image.shape\n",
        "\n",
        "    # determine the new size of the image\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "\n",
        "    # resize the image to the new size\n",
        "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    # embed the image into the standard letter box\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    '''\n",
        "    rescale yolo output boxes from image size used by network to original input\n",
        "    image size\n",
        "\n",
        "    Arguments:\n",
        "     - boxes: list of boxes output by yolo model\n",
        "     - image_h: height of input image\n",
        "     - image_w: width of input image\n",
        "     - net_h: input height required for neural network\n",
        "     - net_w: input width required for neural network\n",
        "    \n",
        "    No return; input boxes list is modified to contain adjusted boxes\n",
        "    '''\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "        \n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        \n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "\n",
        "\n",
        "def draw_boxes(image, boxes, labels, obj_thresh):\n",
        "    '''\n",
        "    Draw boxes output by yolo on input image\n",
        "\n",
        "    Arguments:\n",
        "     - image: a numpy array with an input image\n",
        "     - boxes: list of boxes output by yolo model\n",
        "     - labels: object type label associated with each box\n",
        "     - obj_thresh: minimum threshold for object class probability to include box\n",
        "    \n",
        "    Return:\n",
        "     - updated numpy array for image augmented with boxes and class labels\n",
        "    '''\n",
        "    for box in boxes:\n",
        "        label_str = ''\n",
        "        label = -1\n",
        "        \n",
        "        for i in range(len(labels)):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label_str += labels[i]\n",
        "                label = i\n",
        "                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n",
        "                \n",
        "        if label >= 0:\n",
        "            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n",
        "            cv2.putText(image, \n",
        "                        label_str + ' ' + str(box.get_score()), \n",
        "                        (box.xmin, box.ymin - 13), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                        1e-3 * image.shape[0], \n",
        "                        (0,255,0), 2)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QRWP_cDJ9eg",
        "colab_type": "text"
      },
      "source": [
        "# Generate Predictions\n",
        "\n",
        "The following code reads in the picture of Dino on the couch and generates predictions.  You can run this code as is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAMuFJdhKLl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = \"/content/drive/My Drive/stat344ne_yolo/Dino.png\"\n",
        "\n",
        "# set some configuration parameters\n",
        "# input dimensions for network\n",
        "net_h, net_w = 416, 416\n",
        "\n",
        "# specifications of anchor box widths and heights; more on this next\n",
        "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
        "\n",
        "# Specifications of labels for MSCOCO data set.\n",
        "# Not sure why they chose these classes?\n",
        "# Note that our version of YOLO will only be able to classify into these 80\n",
        "# classes.\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "# Read in the image and preprocess using utility functions defined above\n",
        "# This resizes the image to expected network input dimensions\n",
        "image = cv2.imread(image_path)\n",
        "image_h, image_w, _ = image.shape\n",
        "new_image = preprocess_input(image, net_h, net_w)\n",
        "\n",
        "# Generate the prediction\n",
        "yolos = yolov3.predict(new_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl39cMxd-6DM",
        "colab_type": "text"
      },
      "source": [
        "You may recall I mentioned briefly that the YOLO model makes predictions at multiple scales.  The model predictions contain one set of predictions based on a $13 \\times 13$ grid of cells, a second set of predictions based on a $26 \\times 26$ grid of cells, and a third based on a $52 \\times 52$ grid of cells.  This allows the method to detect objects of different sizes in the image.  Each of these has its own set of 3 anchor boxes with different width and height.  This is described briefly in Section 2.3 of the paper about version 3 of YOLO a https://pjreddie.com/media/files/papers/YOLOv3.pdf.\n",
        "\n",
        "The code below prints out the shapes of each of these separate arrays of anchor box predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoHOXRIHMYGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "814490f1-1d72-4ef2-d34b-20543e502ad9"
      },
      "source": [
        "print(\"first shape  = \" + str(yolos[0].shape))\n",
        "print(\"second shape = \" + str(yolos[1].shape))\n",
        "print(\"third shape  = \" + str(yolos[2].shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first shape  = (1, 13, 13, 255)\n",
            "second shape = (1, 26, 26, 255)\n",
            "third shape  = (1, 52, 52, 255)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4K5tf6uM1DY",
        "colab_type": "text"
      },
      "source": [
        "#### 1) Why is there a leading 1 on the shapes of each of the arrays above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evjODyBJM8B2",
        "colab_type": "text"
      },
      "source": [
        "We made a prediction for a single image.  In Keras, the first element of the shape is the number of observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBTl2k4iM-4J",
        "colab_type": "text"
      },
      "source": [
        "#### 2) Why is the last dimension of the array 255?\n",
        "\n",
        "The code below is a hint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqQ8xJBGNMnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5ddf5f79-4354-49c0-f199-539973cedb8e"
      },
      "source": [
        "print(\"255/3 = \" + str(255/3))\n",
        "print(\"len(labels) = \" + str(len(labels)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255/3 = 85.0\n",
            "len(labels) = 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qemuW-pDNIlX",
        "colab_type": "text"
      },
      "source": [
        "The length of the last dimension is 3*(1 + 4 + 80) because there are 3 anchor boxes, 1 entry per anchor box for the probability there is an object associated with that anchor box, 4 entries per anchor box for the location of the bounding box, and 80 entries per anchor box for class probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1OvgkMMz6y-",
        "colab_type": "text"
      },
      "source": [
        "# Utility functions to decode network outputs -- modifications required\n",
        "\n",
        "The following function takes output from network and turns it into predictions of bounding box location, probability there is an object, and object class probabilities.  Note that the output from the network above has not yet had any transformations or activation functions applied to it.  You will need to apply sigmoid activations to all entries for classification and the appropriate transformations to the other entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIwNpA-1z5PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "    '''\n",
        "    Decode output from the yolo network for a single image.\n",
        "\n",
        "    Arguments:\n",
        "     - netout: numpy array of shape (grid_h, grid_w, 255) with predictions for\n",
        "       one image\n",
        "     - anchors: list of length 6 with width and heigh of each of 3 anchor boxes\n",
        "       in order [box1_w, box1_h, box2_w, box2_h, box3_w, box3_h]\n",
        "     - obj_thresh: minimum probability threshold for an object to keep it in the\n",
        "       list of boxes\n",
        "     - net_h, net_w: width and height of input to yolo network\n",
        "    \n",
        "    Returns:\n",
        "     - a list of bounding boxes for objects in the image.\n",
        "    '''\n",
        "    # extract number of grid cells\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "\n",
        "    # number of anchor boxes\n",
        "    nb_box = 3\n",
        "\n",
        "    # reshape output.  After this, the network output array has shape\n",
        "    # (grid_h, grid_w, 3, 85).  This separates the predicted values for each\n",
        "    # anchor box to make indexing for each anchor box easier.\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\n",
        "    # determing the number of classes.\n",
        "    # (This is a very involved way of calculating 80 = 85 - 5)\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    # Initialize an empty list of boxes.  This will be populated with boxes.\n",
        "    boxes = []\n",
        "\n",
        "    # Apply sigmoid transformation to the predictions of offset for the center\n",
        "    # coordinates of the object.  Notes:\n",
        "    #  * These are in positions 0 and 1 of the last dimension of the netout array\n",
        "    #  * You can simultaneously apply the sigmoid across all grid cells and\n",
        "    #    anchor boxes with a single function call.\n",
        "    #  * Note netout[:, :, :, :2] or netout[..., :2] accesses all entries in the\n",
        "    #    first three dimensions of the array and up to but not including entry 2\n",
        "    #    in the last dimension\n",
        "    #  * In this notebook, the function is defined as _sigmoid\n",
        "    # \n",
        "    # Replace None with appropriate indexing and a call to _sigmoid\n",
        "    netout[..., :2] = _sigmoid(netout[..., :2])\n",
        "    \n",
        "    # Apply exponential transformation to the predictions of multipliers for box\n",
        "    # width and height, in positions 2 and 3 of the last dimension of the netout\n",
        "    # array.  Use np.exp() and indexing similar to above.\n",
        "    netout[..., 2:4] = np.exp(netout[..., 2:4])\n",
        "\n",
        "    # Apply sigmoid activation to the prediction of the probability that this\n",
        "    # cell is associated with an object, in position 4 of the last dimension of\n",
        "    # the netout array.\n",
        "    netout[..., 4] = _sigmoid(netout[..., 4])\n",
        "\n",
        "    # Apply sigmoid activation to the predictions of the probability that this\n",
        "    # cell has an object of each possible class, given that it has an object.\n",
        "    # These are in positions 5 and later in the netout array.\n",
        "    netout[..., 5:] = _sigmoid(netout[..., 5:])\n",
        "\n",
        "    # For each possible object type, compute the probability that each\n",
        "    # combination of cell and anchor box contains an object of that type,\n",
        "    # P(object and specified type) = P(object) * P(object of specified type | object)\n",
        "    netout[..., 5:] = netout[..., 4:5] * netout[..., 5:]\n",
        "\n",
        "    # Thresholding on object probabilities.  Our goal is to only keep objects\n",
        "    # that have at least probability obj_thresh of being an object of a\n",
        "    # specified type.  We'll do this in two steps:\n",
        "    #  1) compute mask, which is 1 if P(object and specified type) > obj_thresh\n",
        "    #     and 0 otherwise\n",
        "    #  2) update the class probabilities to be their current values * the mask\n",
        "    #     the result is 0 if the mask is 0, and no change to the class\n",
        "    #     probabilities if the mask is 1.\n",
        "    # Effectively, this keeps class probabilities unchanged if they are larger\n",
        "    # than the obj_thresh, and sets them to 0 (to ignore) if they are less than\n",
        "    # or equal to the obj_thresh\n",
        "    mask = netout[..., 5:] > obj_thresh\n",
        "    netout[..., 5:] *= mask\n",
        "\n",
        "    # We now iterate through all grid cells and anchor boxes, and extract the\n",
        "    # information for each of them\n",
        "    for row in range(grid_h):\n",
        "        for col in range(grid_w):\n",
        "            for b in range(nb_box):\n",
        "                # first 4 elements are b_x, b_y, b_w, and b_h\n",
        "                b_x, b_y, b_w, b_h = netout[row, col, b, :4]\n",
        "\n",
        "                # element in position 4 is objectness score\n",
        "                objectness = netout[row, col, b, 4]\n",
        "                if(objectness == 0.0): continue\n",
        "                \n",
        "                # last elements are class probabilities\n",
        "                classes = netout[row, col, b, 5:]\n",
        "\n",
        "                # anchor width and height\n",
        "                anchor_w = anchors[2 * b + 0]\n",
        "                anchor_h = anchors[2 * b + 1]\n",
        "\n",
        "                # Compute width and height of bounding box based on anchor_w,\n",
        "                # anchor_h, b_w, and b_h\n",
        "                bbox_w = anchor_w * b_w\n",
        "                bbox_h = anchor_h * b_h\n",
        "\n",
        "                # Compute center of bounding box as proportion of image width\n",
        "                # and height\n",
        "                bbox_x = (col + b_x) / grid_w\n",
        "                bbox_y = (row + b_y) / grid_h\n",
        "\n",
        "                # Rescale width and height of bounding box to proportion of\n",
        "                # image width and height\n",
        "                bbox_w = bbox_w / net_w\n",
        "                bbox_h = bbox_h / net_h\n",
        "                \n",
        "                # Create box object with relative coordinates of upper left and\n",
        "                # lower right bounding box coordinates, P(object), and\n",
        "                # P(object and class) values\n",
        "                bbox = BoundBox(\n",
        "                    bbox_x-bbox_w/2, bbox_y-bbox_h/2,\n",
        "                    bbox_x+bbox_w/2, bbox_y+bbox_h/2,\n",
        "                    objectness,\n",
        "                    classes)\n",
        "\n",
        "                boxes.append(bbox)\n",
        "\n",
        "    return boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY7cXSH6gXKL",
        "colab_type": "text"
      },
      "source": [
        "The code below runs the image processing 3 times with different values of the object probability threshold `obj_thresh`.  It then saves the resulting files in google drive with your name at the beginning.  Take a look at the files in google drive, and answer the question below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaqOiRJbgXnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "2f09180d-f9f0-4d6b-c320-0d5a483ec4db"
      },
      "source": [
        "# Please enter your name here.  For example I might put my_name = 'evan'\n",
        "my_name = 'evan'\n",
        "\n",
        "obj_thresh_vals = [0.01, 0.5, 0.9]\n",
        "\n",
        "for obj_thresh in obj_thresh_vals:\n",
        "    print(\"\\n obj_thresh = \" + str(obj_thresh))\n",
        "    # Regenerate the prediction (we already did this above -- we need to do it\n",
        "    # again here since the decode_netout function modifies the prediction array\n",
        "    image = cv2.imread(image_path)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    new_image = preprocess_input(image, net_h, net_w)\n",
        "    yolos = yolov3.predict(new_image)\n",
        "\n",
        "    boxes = []\n",
        "    for i in range(len(yolos)):\n",
        "        # decode the output of the network\n",
        "        boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, net_h, net_w)\n",
        "\n",
        "    # correct the sizes of the bounding boxes\n",
        "    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "    # draw bounding boxes on the image using labels\n",
        "    draw_boxes(image, boxes, labels, obj_thresh) \n",
        "\n",
        "    # write the image with bounding boxes to file\n",
        "    file_name = image_path[:-4] + '_' + my_name + '_' + str(obj_thresh) + '_detected' + image_path[-4:]\n",
        "    cv2.imwrite(file_name, (image).astype('uint8'))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " obj_thresh = 0.01\n",
            "sink: 1.3248303905129433%\n",
            "sofa: 6.179864704608917%\n",
            "cat: 1.893511414527893%\n",
            "dog: 87.05536127090454%\n",
            "teddy bear: 1.8391726538538933%\n",
            "chair: 1.3590497896075249%\n",
            "sofa: 86.49919033050537%\n",
            "dog: 2.234449051320553%\n",
            "chair: 3.7241321057081223%\n",
            "sofa: 82.71430730819702%\n",
            "sofa: 2.158830128610134%\n",
            "chair: 1.0314123705029488%\n",
            "sofa: 98.93141984939575%\n",
            "sofa: 92.07996129989624%\n",
            "chair: 1.2433595024049282%\n",
            "sofa: 76.88549757003784%\n",
            "sofa: 2.9111532494425774%\n",
            "sofa: 98.55548739433289%\n",
            "sofa: 83.05723667144775%\n",
            "sofa: 9.404147416353226%\n",
            "tvmonitor: 1.2800831347703934%\n",
            "clock: 9.829282760620117%\n",
            "dog: 4.911653324961662%\n",
            "teddy bear: 3.031836450099945%\n",
            "dog: 4.655338451266289%\n",
            "teddy bear: 16.001227498054504%\n",
            "\n",
            " obj_thresh = 0.5\n",
            "dog: 87.05536127090454%\n",
            "sofa: 86.49919033050537%\n",
            "sofa: 82.71430730819702%\n",
            "sofa: 98.93141984939575%\n",
            "sofa: 92.07996129989624%\n",
            "sofa: 76.88549757003784%\n",
            "sofa: 98.55548739433289%\n",
            "sofa: 83.05723667144775%\n",
            "\n",
            " obj_thresh = 0.9\n",
            "sofa: 98.93141984939575%\n",
            "sofa: 92.07996129989624%\n",
            "sofa: 98.55548739433289%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGSEURiOjYQA",
        "colab_type": "text"
      },
      "source": [
        "#### 3) Take a look at the images that were created and saved in the google drive with boxes on them.  Comment in a sentence or two on how the object detection threshold affects the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzWtI4CtkKHK",
        "colab_type": "text"
      },
      "source": [
        "When a smaller object detection threshold is used, more boxes are kept.  Some of them have labels that are clearly incorrect, such as 'clock' for the lamp.  But it did find a lamp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIllyRntvwM3",
        "colab_type": "text"
      },
      "source": [
        "# Intersection over Union and non-max suppression\n",
        "\n",
        "To eliminate duplicate boxes for the same detected object, we must implement non-max suppression based on an evaluation of the intersection over union metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fljt_PjPvwlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    '''\n",
        "    Calculate the length of the overlap between two intervals a and b\n",
        "\n",
        "    Arguments:\n",
        "     - interval_a: a list of floats [x1, x2] with x1 < x2\n",
        "     - interval_b: a list of floats [x3, x4] with x3 < x4\n",
        "    \n",
        "    Returns:\n",
        "     - The length of the overlap between the intervals.  Take cases:\n",
        "        * If the left and right endpoints of interval_b are both less than x1,\n",
        "          overlap is 0\n",
        "        * If the left endpoint of interval_b is less than x1 but the right\n",
        "          endpoint of interval_b is greater than x1, there is some overlap:\n",
        "          the smaller of the right endpoints minus x1\n",
        "        * The same logic also applies with the intervals in the other order\n",
        "    '''\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    '''\n",
        "    Calculate the intersection over union for two boxes\n",
        "\n",
        "    Arguments:\n",
        "     - box1, box2: objects of class BoundBox\n",
        "    \n",
        "    Return:\n",
        "     - The intersection over union of box1 and box2\n",
        "    '''\n",
        "    # Calculate the intersection area.  Do this in three steps:\n",
        "    #  1. Find the interval overlap of the boxes along the horizontal axis\n",
        "    #     using the _interval_overlap function defined above\n",
        "    #  2. Find the interval overlap of the boxes along the vertical axis\n",
        "    #     using the _interval_overlap function defined above\n",
        "    #  3. Find the product of the interval overlap along the horizontal and\n",
        "    #     vertical axes.\n",
        "    \n",
        "    # assemble lists of box coordinates suitable for use as arguments to\n",
        "    # _interval_overlap\n",
        "    box1_horiz_coords = [box1.xmin, box1.xmax]\n",
        "    box1_vert_coords = [box1.ymin, box1.ymax]\n",
        "    box2_horiz_coords = [box2.xmin, box2.xmax]\n",
        "    box2_vert_coords = [box2.ymin, box2.ymax]\n",
        "    \n",
        "    # call _interval_overlap to find the horizontal overlap of the boxes\n",
        "    intersect_horiz = _interval_overlap(box1_horiz_coords, box2_horiz_coords)\n",
        "\n",
        "    # call _interval_overlap to find the vertical overlap of the boxes\n",
        "    intersect_vert = _interval_overlap(box1_vert_coords, box2_vert_coords)\n",
        "    \n",
        "    # find the area of the intersection\n",
        "    intersect = intersect_horiz * intersect_vert\n",
        "\n",
        "    # assemble box widths and heights\n",
        "    w1 = box1.xmax-box1.xmin\n",
        "    h1 = box1.ymax-box1.ymin\n",
        "    w2 = box2.xmax-box2.xmin\n",
        "    h2 = box2.ymax-box2.ymin\n",
        "\n",
        "    # find the area of the union.  Recall that\n",
        "    # |A union B| = |A| + |B| - |A intersection B|\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    # find the intersection over union\n",
        "    iou = intersect / union\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "\n",
        "def do_nms(boxes, nms_thresh):\n",
        "    '''\n",
        "    Do non-max suppression\n",
        "\n",
        "    Arguments:\n",
        "     - boxes: list of boxes identified by predict method\n",
        "       Note that boxes[i].classes[c] is the predicted probability of class c for\n",
        "       box number i\n",
        "     - nms_thresh: probability threshold for non-max suppression\n",
        "    \n",
        "    Return:\n",
        "     - reduced set of boxes after non-max suppression\n",
        "    '''\n",
        "    # If any boxes were found, extract the number of classes (80)\n",
        "    # otherwise, return because there's nothing to do.\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "    \n",
        "    # For each class, do non-max suppression.\n",
        "    # Recall the overall procedure for one class:\n",
        "    # 1. Put the boxes in order from highest probability to lowest for the class\n",
        "    #    currenty under consideration\n",
        "    # 2. Repeat until there are no boxes remaining:\n",
        "    #     a. Choose the box i with highest probability for the class currently\n",
        "    #        under consideration\n",
        "    #     b. For each remaining box j, calculate the IOU between boxes i and j.\n",
        "    #        If the IOU is > nsm_thresh, eliminate box j from consideration for\n",
        "    #        this class (set its predicted probability for this class to 0)\n",
        "\n",
        "    # loop over classes being predicted (loop runs from c = 0 to c = 79)\n",
        "    for c in range(nb_class):\n",
        "        # First, we need to determine how the boxes should be ordered from\n",
        "        # highest probability for class c to lowest.  Sort functions typically\n",
        "        # sort in increasing order, though.  A trick to get around this is to\n",
        "        # sort in increasing order of negative class probability:\n",
        "        # if p1 > p2, then -p1 < -p2, so when sorted p1 will be placed first\n",
        "\n",
        "        # Use a list comprehension to create a list containing -1 * the\n",
        "        # probability of class c for each box in boxes.\n",
        "        # You will need to access box.classes[c] if box is one of the boxes\n",
        "        neg_box_probs = [-box.classes[c] for box in boxes]\n",
        "\n",
        "        # the numpy argsort creates a vector of indices that would sort its\n",
        "        # argument.  For instance, after the call below,\n",
        "        # neg_box_probs[sorted_indices[0]] < neg_box_probs[sorted_indices[1]]\n",
        "        # You may be interested in checking out the documentation at\n",
        "        # https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
        "        sorted_indices = np.argsort(neg_box_probs)\n",
        "\n",
        "        # Loop over the sorted indices\n",
        "        for i in range(len(sorted_indices)):\n",
        "            # index_i is the index of the box that assigned i'th highest\n",
        "            # probability to class c\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            # if this box assigns probability 0 to class c, skip it\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            # otherwise, loop through all boxes that initially assigned lower\n",
        "            # probability to class c than box i\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                # get index for box j\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                # calculate the IOU for boxes at indices index_i and index_j\n",
        "                # using the bbox_iou function defined above\n",
        "                iou = bbox_iou(boxes[index_i], boxes[index_j])\n",
        "\n",
        "                # if the IOU is >= nms_thresh, set the probability of class c\n",
        "                # for the box at index_j to 0\n",
        "                if iou >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZUcQ3fTxxYd",
        "colab_type": "text"
      },
      "source": [
        "Now, run the code below.  This is the same code as you ran above, but with one extra line to do non-max suppression with `nms_thresh = 0.45`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jY_7QSy-8XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e898a55f-77a9-40c2-c290-089339a689a8"
      },
      "source": [
        "# Regenerate the prediction\n",
        "image = cv2.imread(image_path)\n",
        "image_h, image_w, _ = image.shape\n",
        "new_image = preprocess_input(image, net_h, net_w)\n",
        "yolos = yolov3.predict(new_image)\n",
        "\n",
        "obj_thresh = 0.5\n",
        "nms_thresh = 0.45\n",
        "\n",
        "boxes = []\n",
        "for i in range(len(yolos)):\n",
        "    # decode the output of the network\n",
        "    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, net_h, net_w)\n",
        "\n",
        "# correct the sizes of the bounding boxes\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "# suppress non-maximal boxes\n",
        "do_nms(boxes, nms_thresh)     \n",
        "\n",
        "# draw bounding boxes on the image using labels\n",
        "draw_boxes(image, boxes, labels, obj_thresh) \n",
        "\n",
        "# write the image with bounding boxes to file\n",
        "cv2.imwrite(image_path[:-4] + '_' + my_name + '_detected_final' + image_path[-4:], (image).astype('uint8'))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog: 87.05536127090454%\n",
            "sofa: 98.93141984939575%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tri6J1x_yGFJ",
        "colab_type": "text"
      },
      "source": [
        "#### 4) Take a look at your output image.  Comment in a sentence or two on how non-max suppression affects the output of the method, and how it differs from the object detection threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tWPWknUyTS_",
        "colab_type": "text"
      },
      "source": [
        "We now have only one detected box for each object.  Non-max suppression eliminates duplicate boxes for the same object type, while the object detection threshold eliminates all boxes for low-probability objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye5qqJlPy89P",
        "colab_type": "text"
      },
      "source": [
        "You might want to run the method on another photo, like the one of Benedict in the google drive folder :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEMsleFOzB6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "80dcb343-a78d-4da7-cfcd-4bff889957d4"
      },
      "source": [
        "image_path = \"/content/drive/My Drive/stat344ne_yolo/benedict.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image_h, image_w, _ = image.shape\n",
        "new_image = preprocess_input(image, net_h, net_w)\n",
        "yolos = yolov3.predict(new_image)\n",
        "\n",
        "obj_thresh = 0.5\n",
        "nms_thresh = 0.45\n",
        "\n",
        "boxes = []\n",
        "for i in range(len(yolos)):\n",
        "    # decode the output of the network\n",
        "    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, net_h, net_w)\n",
        "\n",
        "# correct the sizes of the bounding boxes\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\n",
        "# suppress non-maximal boxes\n",
        "do_nms(boxes, nms_thresh)     \n",
        "\n",
        "# draw bounding boxes on the image using labels\n",
        "draw_boxes(image, boxes, labels, obj_thresh) \n",
        "\n",
        "# write the image with bounding boxes to file\n",
        "cv2.imwrite(image_path[:-4] + '_' + my_name + '_detected_final' + image_path[-4:], (image).astype('uint8'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: 99.58126544952393%\n",
            "sofa: 93.96252036094666%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfGxAwD3zO6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}